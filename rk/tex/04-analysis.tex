\chapter{Аналитический раздел}

%\text{(англ. \textit{multithreading})}
В данном разделе будут рассмотрены многопоточность, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя, иерархические алгоритмы, алгоритм дивизимной иерархической кластеризации, алгоритм дивизимной иерархической кластеризации и алгоритм k-средних.

\section{Многопоточность}

Многопоточность~---~это возможность центрального процессора одновременно выполнять несколько потоков, используя ресурсы одного процессора. 
Поток представляет собой набор инструкций, которые могут исполняться параллельно с другими потоками того же процесса~\cite{multithreading}.

Процесс~---~это программа в процессе выполнения. Запуск программы или приложения создает процесс, который может включать в себя один или несколько потоков. Поток, будучи частью процесса, выполняет задачи приложения. Процесс завершается, когда все его потоки завершают работу. Каждый поток в операционной системе рассматривается как задача для процессора. Современные процессоры способны выполнять несколько задач на одном ядре, создавая виртуальные ядра, или имеют несколько физических ядер, что характерно для многоядерных процессоров~\cite{process}. 

При разработке многопоточной программы важно учитывать, что простое последовательное выполнение потоков не раскрывает весь потенциал многопоточности. 
Эффективность достигается за счет параллельного выполнения независимых потоков, что сокращает общее время выполнения процесса.

Основной проблемой многопоточности является совместный доступ к общим ресурсам. 
Ключевое ограничение заключается в предотвращении одновременной записи в одну и ту же область памяти из нескольких потоков.
В этом контексте важную роль играет "мьютекс" (от англ. mutex --- mutual exclusion, взаимное исключение), который представляет собой примитив синхронизации. Мьютекс позволяет потокам работать с данными в монопольном режиме, предотвращая одновременный доступ. 
Если два потока пытаются захватить один и тот же мьютекс, только один из них сможет это сделать, а второй будет ожидать его освобождения~\cite{process}.

Инструкции, выполняемые между захватом и освобождением мьютекса, образуют так называемую \textit{критическую секцию}.
Поскольку другие потоки не могут выполнить критическую секцию, пока мьютекс захвачен, важно минимизировать объем и продолжительность критической секции во избежание задержек в выполнении~\cite{process}.

\section{Алгоритмы классификации полнотекстовых документов}

Классификация текстов~---~ключевая задача в компьютерной лингвистике, охватывающая алгоритмы с учителем и без учителя, и имеющая важное значение для обеспечения информационной безопасности.
Алгоритмы с учителем используют предварительно размеченные данные для обучения, в то время как алгоритмы без учителя, такие как кластеризация, организуют данные на основе внутренних закономерностей~\cite{main-book}.

В данной лабораторной работе исследуется применение алгоритмов классификации без учителя для определения групп документов с помощью метода иерархической кластеризации с дивизимным подходом. 
Целью является выявление кластеров документов, таким образом, чтобы документы внутри одного кластера были максимально схожи по смыслу, а документы из различных кластеров~---~значительно отличались.
Особенность данного подхода заключается в отсутствии необходимости в предварительной разметке данных и определении количества кластеров, что открывает широкие возможности для анализа неструктурированных данных~\cite{main-book}.
Кластеризация~---~это разбиение элементов некоторого множества на группы по принципу схожести. Эти группы принято называть кластерами~\cite{defcluctering}.


\section{Алгоритмы классификации без учителя}

Алгоритмы классификации без учителя разбивают набор документов на группы, где одна группа содержит родственные документы, а разные группы содержат разные документы. 
Без обучающего подмножества и известных категорий, алгоритм кластеризации автоматически определяет количество и состав кластеров, используя расстояния между документами~\cite{main-book}.

Кластеризация текстов основана на идее, что похожие документы подходят к одним и тем же запросам, а разные документы подходят к разным запросам~\cite{main-book}.

Исследование проводится над набором документов вида:
\begin{equation}\label{eq:doc}
	D = \{d_j\,|\,j=1,\ldots,|D|\},
\end{equation}
содержащей разнообразные тематические классы.
Цель алгоритмов классификации без учителя~---~автоматически классифицировать документы на кластеры вида:
\begin{equation}\label{eq:claster}
	C = \{c_j\,|\,j=1,\ldots,|C|\},
\end{equation}
так чтобы каждый кластер представлял собой группу тематически схожих документов. 
Задача кластеризации сводится к определению оптимального множества кластеров \( C \), удовлетворяющего заданным критериям качества~\cite{main-book}.

\section{Иерархические алгоритмы}

Иерархические алгоритмы создают структурированное множество кластеров~---~иерархию, которое может оказаться весьма информативным для некоторых приложений~\cite{main-book}.

В рамках иерархической кластеризации существуют агломеративные (восходящие) и дивизимные (нисходящие) подходы. 
Агломеративные методы последовательно объединяют мелкие кластеры в более крупные, в то время как дивизимные методы начинают с одного большого кластера и делят его на более мелкие. 
Дивизимные методы часто требуют дополнительных алгоритмов для определения способа разделения и могут быть более эффективными при ограничении процесса до верхних уровней иерархии без полного разделения на индивидуальные документы.
Сложность дивизимного алгоритма зависит от выбранного дополнительного алгоритма плоской кластеризации, если выбран алгоритм k-средних, то $O(|D|)$~\cite{main-book}.

\section{Представление данных в задаче}

В данной лабораторной работе рассматривается использование иерархической кластеризации для анализа текстовых документов. 
Основа алгоритма~---~представление документов в виде векторов терминов с весами, вычисленными по методу \textit{TF-IDF}.

\textbf{Входные данные}

Для каждого документа в наборе вида (\ref{eq:doc}) формируется вектор:
\begin{equation}\label{eq:term}
\mathbf{d}_i = (d_{i1}, \ldots, d_{iT}), 
\end{equation}
где \( T \)~---~количество уникальных терминов во всех документах, а \( d_{ij} \)~---~вес  \( j \)-го термина в \( i \)-м документе.

\textbf{Вычисление весов терминов}

Веса терминов рассчитываются по формулам:
\begin{equation}\label{eq:term_weight}
d_{ij} = \frac{w_{ij}}{\|\mathbf{w}_i\|}, 
\end{equation}

\begin{equation}\label{eq:sub_term_weight}
w_{ij} = tf_{ij} \times \log\left(\frac{|D|}{df_j}\right).
\end{equation} 

В формулах~(\ref{eq:term_weight})~--~(\ref{eq:sub_term_weight}) \textbf{используются следующие} обозначения: \( tf_{ij} \)~---~частота \( j \)-го термина в \( i \)-м документе, \( |D| \) --- общее количество документов в наборе, \( df_j \)~---~документная частота термина \( j \), и \( \|\mathbf{w}_i\| \)~---~евклидова норма вектора весов \( i \)-го документа.

\textbf{Выходные данные}

Алгоритм генерирует структуру кластеров, представленную иерархическим деревом, и метки кластеров вида (\ref{eq:claster}), характеризующие группы родственных документов.

\section {Алгоритм дивизимной иерархической кластеризации}

\begin{enumerate}
	\item Вход: множество проиндексированных документов $D$ вида~(\ref{eq:doc}).
	\item Вычислить веса терминов для каждого документа с использованием метода \textit{TF-IDF}, по формуле~(\ref{eq:term_weight}).
	\item Изначально все элементы принадлежат одному кластеру $C_i$, $i = 0$ (\ref{eq:doc}).
	\item Разделить кластер на два подкластера $C_{i+1}$ и $C_{i+2}$.
	\item Применить алгоритм \textit{k-средних} к подкластерам $C_{i+1}$ и $C_{i+2}$. 
	\item Увеличить $i$ и повторить шаги 4 и 5 до достижения желаемой структуры кластеризации.
	\item Возвратить итоговую структуру кластеров.
\end{enumerate}


\section{Алгоритм k-средних}

При заранее известном числе кластеров \( k \), алгоритм k-средних начинает с некоторого начального разбиения документов и уточняет его, оптимизируя целевую функцию – среднеквадратичную ошибку кластеризации как среднеквадратичное расстояние между документами и центрами их кластеров:

\begin{equation}
	e(D, C) = \sum_{j=1}^{k} \sum_{i:d_i \in C_j} \left\| d_i - \mu_j \right\|^2,
\end{equation}
где \( \mu_j \)~---~центр, или центроид, кластера \( C_j \), \( |C| = k \), вычисляющийся по формуле
\begin{equation}
	\mu_j = \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i,
\end{equation}
где \( |C_j| \)~---~количество документов в \( C_j \). Идеальным кластером алгоритм k~-~средних считает сферу с центроидом в центре сферы.

Алгоритм k-средних состоит из следующих шагов~\cite{main-book}.
\begin{enumerate}
	\item \textit{Вход:} множество проиндексированных документов \( D \), количество кластеров \( k \). % Исходные данные для кластеризации
	\item Назначить начальные центры для кластеров \( \{ \mu_j \},\ j = 1,\ ...,\ k \) случайным образом. % Начальное приближение
	\item Установить каждому кластеру \( C_j \) пустой набор, \( j = 1,\ ...,\ k \). % Подготовка к итерациям
	\item Для каждого документа \( d_i \in D \) выполнить: % Распределение документов по кластерам
	\begin{itemize}
		\item найти ближайший центр кластера \( j^* := \arg \min_j \left\| \mu_j - d_i \right\|,\ j = 1,\ ...,\ k; \) % Определение ближайшего центра
		\item добавить документ \( d_i \) в соответствующий кластер \( C_{j^*} := C_{j^*} \cup \{d_i\}. \) % Обновление кластера
	\end{itemize}
	\item Для каждого кластера \( C_j \) обновить центр как среднее его элементов: % Перерасчет центров
	\[ \mu_j := \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i. \]
	\item Если условие остановки не достигнуто, вернуться к шагу 4. % Критерий остановки итерационного процесса
	\item \textit{Выход:} множество центров кластеров \( \{ \mu_j \} \) и множество самих кластеров \( C \). % Результат кластеризации
\end{enumerate}

\section *{Вывод}
В данном разделе были рассмотрены многопоточность, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя, иерархические алгоритмы, алгоритм дивизимной иерархической кластеризации, алгоритм дивизимной иерархической кластеризации и алгоритм k-средних.

\if 0
\section{Модифицированный алгоритм k-средних для дивизимной кластеризации}

В модифицированном алгоритме k-средних для дивизимной иерархической кластеризации изначально весь набор данных представляет собой один большой кластер. Алгоритм постепенно разделяет этот кластер на подкластеры, пока не достигнет нужного уровня иерархии или количество кластеров не сократится до желаемого. Вот пример такого алгоритма:

\begin{enumerate}
	\item Определить количество подкластеров \( k \) для разделения исходного кластера.
	\item Выбрать \( k \) случайных центров из исходного кластера.
	\item Присвоить каждый документ подкластеру на основе близости к центрам.
	\item Пересчитать центры подкластеров как среднее всех документов в подкластере.
	\item Повторять шаги 3 и 4 до сходимости: когда центры подкластеров не меняются или изменения не превышают заданный порог.
	\item Когда условие остановки выполнено, каждый подкластер может быть рассмотрен как отдельный кластер для следующего уровня разделения или в качестве конечного результата кластеризации.
\end{enumerate}

Этот процесс помогает построить иерархическую структуру кластеров, где на каждом уровне данные разбиваются на более мелкие и уточненные кластеры.

\fi
