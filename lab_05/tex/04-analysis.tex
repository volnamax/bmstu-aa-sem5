\chapter{Аналитический раздел}

В данном разделе будут рассмотрены конвейерная обработка данных, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя, иерархические алгоритмы, алгоритм дивизимной иерархической кластеризации, алгоритм дивизимной иерархической кластеризации и алгоритм k-средних.

\section{Конвейерная обработка данных}

Конвейер~--- организация вычислений, при которой увеличивается количество выполняемых инструкций за единицу времени за счет использования принципов параллельности.

Конвейеризация в компьютерной обработке данных основана на разбиении выполнения функций на более мелкие этапы, называемые ступенями, и выделении отдельной аппаратуры для каждой из них.
Это позволяет организовать передачу данных от одного этапа к следующему, что увеличивает производительность за счет одновременного выполнения нескольких команд на различных ступенях конвейера~\cite{conveyor}.

Хотя конвейеризация не уменьшает время выполнения отдельной команды, она повышает пропускную способность процессора, что приводит к более быстрому выполнению программы по сравнению с простой, не конвейерной схемой.


\section{Алгоритмы классификации полнотекстовых документов}

Классификация текстов~---~ключевая задача в компьютерной лингвистике, охватывающая алгоритмы с учителем и без учителя, и имеющая важное значение для обеспечения информационной безопасности.
Алгоритмы с учителем используют предварительно размеченные данные для обучения, в то время как алгоритмы без учителя, такие как кластеризация, организуют данные на основе внутренних закономерностей~\cite{main-book}.

В данной лабораторной работе исследуется применение алгоритмов классификации без учителя для определения групп документов с помощью метода иерархической кластеризации с дивизимным подходом. 
Целью является выявление кластеров документов, таким образом, чтобы документы внутри одного кластера были максимально схожи по смыслу, а документы из различных кластеров~---~значительно отличались.
Особенность данного подхода заключается в отсутствии необходимости в предварительной разметке данных и определении количества кластеров, что открывает широкие возможности для анализа неструктурированных данных~\cite{main-book}.
Кластеризация~---~это разбиение элементов некоторого множества на группы по принципу схожести. Эти группы принято называть кластерами~\cite{defcluctering}.


\section{Алгоритмы классификации без учителя}

Алгоритмы классификации без учителя разбивают набор документов на группы, где одна группа содержит родственные документы, а разные группы содержат разные документы. 
Без обучающего подмножества и известных категорий, алгоритм кластеризации автоматически определяет количество и состав кластеров, используя расстояния между документами~\cite{main-book}.

Кластеризация текстов основана на идее, что похожие документы подходят к одним и тем же запросам, а разные документы подходят к разным запросам~\cite{main-book}.

Исследование проводится над набором документов вида:
\begin{equation}\label{eq:doc}
	D = \{d_j\,|\,j=1,\ldots,|D|\},
\end{equation}
содержащей разнообразные тематические классы.
Цель алгоритмов классификации без учителя~---~автоматически классифицировать документы на кластеры вида:
\begin{equation}\label{eq:claster}
	C = \{c_j\,|\,j=1,\ldots,|C|\},
\end{equation}
так чтобы каждый кластер представлял собой группу тематически схожих документов. 
Задача кластеризации сводится к определению оптимального множества кластеров \( C \), удовлетворяющего заданным критериям качества~\cite{main-book}.

\section{Иерархические алгоритмы}

Иерархические алгоритмы создают структурированное множество кластеров~---~иерархию, которое может оказаться весьма информативным для некоторых приложений~\cite{main-book}.

В рамках иерархической кластеризации существуют агломеративные (восходящие) и дивизимные (нисходящие) подходы. 
Агломеративные методы последовательно объединяют мелкие кластеры в более крупные, в то время как дивизимные методы начинают с одного большого кластера и делят его на более мелкие. 
Дивизимные методы часто требуют дополнительных алгоритмов для определения способа разделения и могут быть более эффективными при ограничении процесса до верхних уровней иерархии без полного разделения на индивидуальные документы.
Сложность дивизимного алгоритма зависит от выбранного дополнительного алгоритма плоской кластеризации, если выбран алгоритм k-средних, то $O(|D|)$~\cite{main-book}.

\section{Представление данных в задаче}

В данной лабораторной работе рассматривается использование иерархической кластеризации для анализа текстовых документов. 
Основа алгоритма~---~представление документов в виде векторов терминов с весами, вычисленными по методу \textit{TF-IDF}.

\textbf{Входные данные}

Для каждого документа в наборе вида (\ref{eq:doc}) формируется вектор:
\begin{equation}\label{eq:term}
	\mathbf{d}_i = (d_{i1}, \ldots, d_{iT}), 
\end{equation}
где \( T \)~---~количество уникальных терминов во всех документах, а \( d_{ij} \)~---~вес  \( j \)-го термина в \( i \)-м документе.

\textbf{Вычисление весов терминов}

Веса терминов рассчитываются по формулам:
\begin{equation}\label{eq:term_weight}
	d_{ij} = \frac{w_{ij}}{\|\mathbf{w}_i\|}, 
\end{equation}

\begin{equation}\label{eq:sub_term_weight}
	w_{ij} = tf_{ij} \times \log\left(\frac{|D|}{df_j}\right).
\end{equation} 

В формулах~(\ref{eq:term_weight})~--~(\ref{eq:sub_term_weight}) используются следующие обозначения: \( tf_{ij} \)~---~частота \( j \)-го термина в \( i \)-м документе, \( |D| \) --- общее количество документов в наборе, \( df_j \)~---~документная частота термина \( j \), и \( \|\mathbf{w}_i\| \)~---~евклидова норма вектора весов \( i \)-го документа.

\textbf{Выходные данные}
Алгоритм генерирует структуру кластеров, представленную иерархическим деревом, и метки кластеров вида (\ref{eq:claster}), характеризующие группы родственных документов.

\section {Алгоритм дивизимной иерархической кластеризации}

\begin{enumerate}
	\item Вход: множество проиндексированных документов $D$ вида~(\ref{eq:doc}).
	\item Вычислить веса терминов для каждого документа с использованием метода \textit{TF-IDF}, по формуле~(\ref{eq:term_weight}).
	\item Изначально все элементы принадлежат одному кластеру $C_i$, $i = 0$ (\ref{eq:claster}).
	\item Разделить кластер на два подкластера $C_{i+1}$ и $C_{i+2}$.
	\item Применить алгоритм \textit{k-средних} к подкластерам $C_{i+1}$ и $C_{i+2}$. 
	\item Увеличить $i$ и повторить шаги 4 и 5 до достижения желаемой структуры кластеризации.
	\item Возвратить итоговую структуру кластеров.
\end{enumerate}


\section{Алгоритм k-средних}

При заранее известном числе кластеров \( k \), алгоритм k-средних начинает с некоторого начального разбиения документов и уточняет его, оптимизируя целевую функцию – среднеквадратичную ошибку кластеризации как среднеквадратичное расстояние между документами и центрами их кластеров:

\begin{equation}
	e(D, C) = \sum_{j=1}^{k} \sum_{i:d_i \in C_j} \left\| d_i - \mu_j \right\|^2,
\end{equation}
где \( \mu_j \)~---~центр, или центроид, кластера \( C_j \), \( |C| = k \), вычисляющийся по формуле
\begin{equation}
	\mu_j = \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i,
\end{equation}
где \( |C_j| \)~---~количество документов в \( C_j \). Идеальным кластером алгоритм k~-~средних считает сферу с центроидом в центре сферы.

Алгоритм k-средних состоит из следующих шагов~\cite{main-book}.
\begin{enumerate}
	\item \textit{Вход:} множество проиндексированных документов \( D \), количество кластеров \( k \). % Исходные данные для кластеризации
	\item Назначить начальные центры для кластеров \( \{ \mu_j \},\ j = 1,\ ...,\ k \) случайным образом. % Начальное приближение
	\item Установить каждому кластеру \( C_j \) пустой набор, \( j = 1,\ ...,\ k \). % Подготовка к итерациям
	\item Для каждого документа \( d_i \in D \) выполнить: % Распределение документов по кластерам
	\begin{itemize}
		\item найти ближайший центр кластера \( j^* := \arg \min_j \left\| \mu_j - d_i \right\|,\ j = 1,\ ...,\ k; \) % Определение ближайшего центра
		\item добавить документ \( d_i \) в соответствующий кластер \( C_{j^*} := C_{j^*} \cup \{d_i\}. \) % Обновление кластера
	\end{itemize}
	\item Для каждого кластера \( C_j \) обновить центр как среднее его элементов: % Перерасчет центров
	\[ \mu_j := \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i. \]
	\item Если условие остановки не достигнуто, вернуться к шагу 4. % Критерий остановки итерационного процесса
	\item \textit{Выход:} множество центров кластеров \( \{ \mu_j \} \) и множество самих кластеров \( C \). % Результат кластеризации
\end{enumerate}

\section *{Вывод}
В данном разделе были рассмотрены конвейерная обработка данных, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя, иерархические алгоритмы, алгоритм дивизимной иерархической кластеризации, алгоритм дивизимной иерархической кластеризации и алгоритм k-средних.

