\chapter{Аналитический раздел}

%\text{(англ. \textit{multithreading})}
В данном разделе будут рассмотрены графовые модели, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя и алгоритм k-средних.



\section{Графовые модели}

Графом системы управления называется граф $G = G(X,U)$, в котором множество вершин \textit{X} интерпретирует множество элементов систем управления, а множество ребер \textit{U} --- множество связей между ними. Важным преимуществом модели в виде графа систем управления является возможность эффективного применения компьютерных технологий для автоматизации обнаружения критических структурных свойств исследуемой СУ~\cite{gu}.

Информационный граф --- орграф информационных связей в программе или схеме программ. Необходимым условием наличия информационной связи между операндами операторов $S_1$ и $S_2$ является существование специального вида пути по управляющему графу от $S_1$ до $S_2$ — маршрута информационной связи, подтверждающего данную информационную связь~\cite{ig}.

Операционная история представляет собой последовательность преобразований, выполняемых при работе программы~\cite{oh}.

Если вершинам графа зависимостей соответствуют отдельные срабатывания  операторов программы, то такой граф называется информационной историей выполнения программы. Информационная история содержит максимально  подробную информацию о структуре информационных зависимостей  анализируемой программы. Поэтому она используется при анализе программ с целью распараллеливания~\cite{ih}.

\section{Алгоритмы классификации полнотекстовых документов}

Классификация текстов~---~ключевая задача в компьютерной лингвистике, охватывающая алгоритмы с учителем и без учителя, и имеющая важное значение для обеспечения информационной безопасности.
Алгоритмы с учителем используют предварительно размеченные данные для обучения, в то время как алгоритмы без учителя, такие как кластеризация, организуют данные на основе внутренних закономерностей~\cite{main-book}.

В данной лабораторной работе исследуется применение алгоритмов классификации без учителя для определения групп документов с помощью метода иерархической кластеризации с дивизимным подходом. 
Целью является выявление кластеров документов, таким образом, чтобы документы внутри одного кластера были максимально схожи по смыслу, а документы из различных кластеров~---~значительно отличались.
Особенность данного подхода заключается в отсутствии необходимости в предварительной разметке данных и определении количества кластеров, что открывает широкие возможности для анализа неструктурированных данных~\cite{main-book}.
Кластеризация~---~это разбиение элементов некоторого множества на группы по принципу схожести. Эти группы принято называть кластерами~\cite{defcluctering}.


\section{Алгоритмы классификации без учителя}

Алгоритмы классификации без учителя разбивают набор документов на группы, где одна группа содержит родственные документы, а разные группы содержат разные документы. 
Без обучающего подмножества и известных категорий, алгоритм кластеризации автоматически определяет количество и состав кластеров, используя расстояния между документами~\cite{main-book}.

Кластеризация текстов основана на идее, что похожие документы подходят к одним и тем же запросам, а разные документы подходят к разным запросам~\cite{main-book}.

Исследование проводится над набором документов вида:
\begin{equation}\label{eq:doc}
	D = \{d_j\,|\,j=1,\ldots,|D|\},
\end{equation}
содержащей разнообразные тематические классы.
Цель алгоритмов классификации без учителя~---~автоматически классифицировать документы на кластеры вида:
\begin{equation}\label{eq:claster}
	C = \{c_j\,|\,j=1,\ldots,|C|\},
\end{equation}
так чтобы каждый кластер представлял собой группу тематически схожих документов. 
Задача кластеризации сводится к определению оптимального множества кластеров \( C \), удовлетворяющего заданным критериям качества~\cite{main-book}.

\section{Алгоритм k-средних}

При заранее известном числе кластеров \( k \), алгоритм k-средних начинает с некоторого начального разбиения документов и уточняет его, оптимизируя целевую функцию – среднеквадратичную ошибку кластеризации как среднеквадратичное расстояние между документами и центрами их кластеров:

\begin{equation}
	e(D, C) = \sum_{j=1}^{k} \sum_{i:d_i \in C_j} \left\| d_i - \mu_j \right\|^2,
\end{equation}
где \( \mu_j \)~---~центр, или центроид, кластера \( C_j \), \( |C| = k \), вычисляющийся по формуле
\begin{equation}
	\mu_j = \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i,
\end{equation}
где \( |C_j| \)~---~количество документов в \( C_j \). Идеальным кластером алгоритм k~-~средних считает сферу с центроидом в центре сферы.

Алгоритм k-средних состоит из следующих шагов~\cite{main-book}.
\begin{enumerate}
	\item \textit{Вход:} множество проиндексированных документов \( D \), количество кластеров \( k \). % Исходные данные для кластеризации
	\item Назначить начальные центры для кластеров \( \{ \mu_j \},\ j = 1,\ ...,\ k \) случайным образом. % Начальное приближение
	\item Установить каждому кластеру \( C_j \) пустой набор, \( j = 1,\ ...,\ k \). % Подготовка к итерациям
	\item Для каждого документа \( d_i \in D \) выполнить: % Распределение документов по кластерам
	\begin{itemize}
		\item найти ближайший центр кластера \( j^* := \arg \min_j \left\| \mu_j - d_i \right\|,\ j = 1,\ ...,\ k; \) % Определение ближайшего центра
		\item добавить документ \( d_i \) в соответствующий кластер \( C_{j^*} := C_{j^*} \cup \{d_i\}. \) % Обновление кластера
	\end{itemize}
	\item Для каждого кластера \( C_j \) обновить центр как среднее его элементов: % Перерасчет центров
	\[ \mu_j := \frac{1}{|C_j|} \sum_{i:d_i \in C_j} d_i. \]
	\item Если условие остановки не достигнуто, вернуться к шагу 4. % Критерий остановки итерационного процесса
	\item \textit{Выход:} множество центров кластеров \( \{ \mu_j \} \) и множество самих кластеров \( C \). % Результат кластеризации
\end{enumerate}


\section *{Вывод}
В данном разделе были рассмотрены графовые модели, алгоритмы классификации полнотекстовых документов, алгоритмы классификации без учителя и алгоритм k-средних.

